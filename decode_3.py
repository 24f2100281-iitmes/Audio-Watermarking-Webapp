# -*- coding: utf-8 -*-
"""Decode-3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GPp9DXVGtwrPkCdJHLQc8tmBWIuhSZhT
"""

import numpy as np
import librosa
import soundfile as sf
import matplotlib.pyplot as plt
from google.colab import files

print("="*60)
print("AUDIO WATERMARKING - DECODING (FFT BASED)")
print("="*60)

# Step 1: Upload Audio Files
print("\nðŸ“ Please upload the ORIGINAL audio file:")
orig_upload = files.upload()
original_file = list(orig_upload.keys())[0]
print(f"âœ“ Original audio loaded: {original_file}")

print("\nðŸ“ Now upload the WATERMARKED audio file:")
wm_upload = files.upload()
watermarked_file = list(wm_upload.keys())[0]
print(f"âœ“ Watermarked audio loaded: {watermarked_file}")

# Step 2: Load audio files
print("\nâš™ï¸ Loading audio files...")

def load_audio(file_path):
    data, sr = librosa.load(file_path, sr=None, mono=True)
    return data, sr

orig, sr1 = load_audio(original_file)
watermarked, sr2 = load_audio(watermarked_file)

print(f"  Original audio: {len(orig)} samples @ {sr1} Hz")
print(f"  Watermarked audio: {len(watermarked)} samples @ {sr2} Hz")

# Match sample rate if needed
if sr1 != sr2:
    watermarked = librosa.resample(watermarked, orig_sr=sr2, target_sr=sr1)
    print(f"  âœ“ Resampled watermarked audio to {sr1} Hz")

# Match length
min_len = min(len(orig), len(watermarked))
orig = orig[:min_len]
watermarked = watermarked[:min_len]

print(f"  âœ“ Audio lengths matched: {min_len} samples")

# Step 3: FFT Transform
print("\nðŸ”„ Performing FFT on both audio files...")

FFT_orig = np.fft.fft(orig)
FFT_watermarked = np.fft.fft(watermarked)

print("  âœ“ FFT transformation complete")

# Step 4: Extract watermark from high-frequency region
print("\nðŸ” Extracting watermark from FFT difference...")

alpha = 0.008  # same embedding strength used during encoding
N = len(FFT_orig)

# High-frequency band (same as encoding - last 30%)
start = int(0.7 * N)

# Extract watermark FFT from the difference
FFT_extracted = np.zeros(N, dtype=complex)
FFT_extracted[start:] = (FFT_watermarked[start:] - FFT_orig[start:]) / alpha

print(f"  Extraction factor (alpha): {alpha}")
print(f"  Frequency band used: {start} to {N}")
print(f"  âœ“ Watermark FFT extracted from high-frequency region")

# Step 5: Inverse FFT to get watermark audio
print("\nðŸ”¨ Reconstructing extracted watermark audio...")

extracted_watermark = np.fft.ifft(FFT_extracted)
extracted_watermark = np.real(extracted_watermark)

# Normalize before trimming
if np.max(np.abs(extracted_watermark)) > 0:
    extracted_watermark /= np.max(np.abs(extracted_watermark))

print("  âœ“ Watermark audio reconstructed and normalized")
print(f"  Initial length: {len(extracted_watermark)} samples ({len(extracted_watermark)/sr1:.2f} sec)")

# Step 6: Remove trailing silence
print("\nâœ‚ï¸ Removing trailing silence...")

def trim_silence(audio, threshold=0.01, frame_length=2048, hop_length=512):
    """
    Trim trailing silence from audio
    threshold: amplitude threshold for silence detection (0.01 = 1% of max)
    """
    # Calculate energy in frames
    energy = np.array([
        np.sqrt(np.mean(audio[i:i+frame_length]**2))
        for i in range(0, len(audio), hop_length)
    ])

    # Find last non-silent frame
    non_silent = np.where(energy > threshold)[0]

    if len(non_silent) > 0:
        last_non_silent_frame = non_silent[-1]
        # Convert frame index to sample index (add some padding)
        cut_point = min(
            (last_non_silent_frame + 2) * hop_length + frame_length,
            len(audio)
        )
        return audio[:cut_point]
    else:
        return audio

# Apply silence trimming
original_length = len(extracted_watermark)
extracted_watermark = trim_silence(extracted_watermark, threshold=0.01)
trimmed_length = len(extracted_watermark)

silence_removed = original_length - trimmed_length
print(f"  âœ“ Removed {silence_removed} samples ({silence_removed/sr1:.2f} sec) of silence")
print(f"  âœ“ Final length: {trimmed_length} samples ({trimmed_length/sr1:.2f} sec)")

# Step 7: Save extracted watermark
output_file = "extracted_watermark.wav"
sf.write(output_file, extracted_watermark, sr1)

print(f"\nâœ… Extracted watermark saved as '{output_file}'")
print(f"   Length: {len(extracted_watermark)} samples @ {sr1} Hz")
print(f"   Duration: {len(extracted_watermark)/sr1:.2f} seconds")

# Step 8: Calculate extraction quality metrics
print("\nðŸ“Š Extraction Quality Metrics:")

signal_power = np.mean(np.abs(FFT_extracted[start:])**2)
energy = np.sum(extracted_watermark**2)

print(f"  Extracted signal power: {signal_power:.6e}")
print(f"  Extracted watermark energy: {energy:.6f}")
print(f"  Silence reduction: {(silence_removed/original_length)*100:.1f}%")

# Step 9: Download result
print("\nðŸ“¥ Downloading extracted watermark...")
files.download(output_file)

print("\n" + "="*60)
print("âœ“ FFT-BASED DECODING COMPLETE!")
print("="*60)
print("\nðŸ’¡ Result:")
print(f"  - Original extracted length: {original_length/sr1:.2f} seconds")
print(f"  - After silence removal: {trimmed_length/sr1:.2f} seconds")
print(f"  - Clean audio with no trailing silence!")
print("="*60)

# Matlab
plt.figure(figsize=(12,6))

plt.subplot(2,1,1)
plt.plot(watermarked)
plt.title("Watermarked (Main) Audio â€“ Time Domain")

plt.subplot(2,1,2)
plt.plot(extracted_watermark)
plt.title("Extracted Short Audio â€“ Time Domain")

plt.tight_layout()
plt.show()